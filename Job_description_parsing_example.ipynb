{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prithikah23/java-projects/blob/master/Job_description_parsing_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkVyoBu8KMpV",
        "outputId": "5aeb87e8-1fe8-41fa-ca0b-9e90ccde0385"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'science': 3, 'computer': 2, 'machine': 2, 'data': 2, 'science related': 2, 'machine learning': 2, 'data science': 2, 'skills': 1, 'bs': 1, 'ms': 1, 'phd': 1, 'engineering': 1, 'field': 1, 'learning': 1, 'models': 1, 'production': 1, 'environments': 1, 'recommendation': 1, 'engines': 1, 'vision': 1, 'systems': 1, 'hands': 1, 'statistics': 1, 'prototypes': 1, 'research': 1, 'papers': 1, 'proficient': 1, 'python': 1, 'pandas': 1, 'r': 1, 'tensorflow': 1, 'amongst': 1, 'tools': 1, 'mind': 1, 'business': 1, 'acumen': 1, 'hungry': 1, 'learn': 1, 'required skills': 1, 'skills :': 1, ': -': 1, '- bs': 1, 'bs (': 1, '( higher': 1, 'higher ,': 1, ', e.g.': 1, 'e.g. ,': 1, ', ms': 1, 'ms ,': 1, ', phd': 1, 'phd )': 1, ') computer': 1, 'computer science': 1, 'related engineering': 1, 'engineering field': 1, 'field involving': 1, 'involving coding': 1, 'coding -': 1, '- experienced': 1, 'experienced implementing': 1, 'implementing scaling': 1, 'scaling machine': 1, 'learning models': 1, 'models production': 1, 'production environments': 1, 'environments (': 1, '( including': 1, 'including recommendation': 1, 'recommendation engines': 1, 'engines and/or': 1, 'and/or computer': 1, 'computer vision': 1, 'vision systems': 1, 'systems )': 1, ') -': 1, '- strong': 1, 'strong understanding': 1, 'understanding machine': 1, 'learning theory': 1, 'theory -': 1, '- hands': 1, 'hands experience': 1, 'experience statistics': 1, 'statistics -': 1, '- capable': 1, 'capable quickly': 1, 'quickly implementing': 1, 'implementing prototypes': 1, 'prototypes cutting-edge': 1, 'cutting-edge research': 1, 'research papers': 1, 'papers -': 1, '- proficient': 1, 'proficient python': 1, 'python (': 1, '( i.e': 1, 'i.e .': 1, '. pandas': 1, 'pandas ,': 1, ', numpy': 1, 'numpy ,': 1, ', scikit-learn': 1, 'scikit-learn ,': 1, ', etc': 1, 'etc )': 1, ') ,': 1, ', r': 1, 'r ,': 1, ', tensorflow': 1, 'tensorflow ,': 1, ', amongst': 1, 'amongst data': 1, 'related tools': 1, 'tools libraries': 1, 'libraries -': 1, '- analytical': 1, 'analytical mind': 1, 'mind strong': 1, 'strong business': 1, 'business acumen': 1, \"acumen 're\": 1, \"'re passionate\": 1, 'passionate data': 1, 'science hungry': 1, 'hungry learn': 1, 'learn ,': 1, ', please': 1, 'please apply': 1, 'apply !': 1, 'required skills :': 1, 'skills : -': 1, ': - bs': 1, '- bs (': 1, 'bs ( higher': 1, '( higher ,': 1, 'higher , e.g.': 1, ', e.g. ,': 1, 'e.g. , ms': 1, ', ms ,': 1, 'ms , phd': 1, ', phd )': 1, 'phd ) computer': 1, ') computer science': 1, 'computer science related': 1, 'science related engineering': 1, 'related engineering field': 1, 'engineering field involving': 1, 'field involving coding': 1, 'involving coding -': 1, 'coding - experienced': 1, '- experienced implementing': 1, 'experienced implementing scaling': 1, 'implementing scaling machine': 1, 'scaling machine learning': 1, 'machine learning models': 1, 'learning models production': 1, 'models production environments': 1, 'production environments (': 1, 'environments ( including': 1, '( including recommendation': 1, 'including recommendation engines': 1, 'recommendation engines and/or': 1, 'engines and/or computer': 1, 'and/or computer vision': 1, 'computer vision systems': 1, 'vision systems )': 1, 'systems ) -': 1, ') - strong': 1, '- strong understanding': 1, 'strong understanding machine': 1, 'understanding machine learning': 1, 'machine learning theory': 1, 'learning theory -': 1, 'theory - hands': 1, '- hands experience': 1, 'hands experience statistics': 1, 'experience statistics -': 1, 'statistics - capable': 1, '- capable quickly': 1, 'capable quickly implementing': 1, 'quickly implementing prototypes': 1, 'implementing prototypes cutting-edge': 1, 'prototypes cutting-edge research': 1, 'cutting-edge research papers': 1, 'research papers -': 1, 'papers - proficient': 1, '- proficient python': 1, 'proficient python (': 1, 'python ( i.e': 1, '( i.e .': 1, 'i.e . pandas': 1, '. pandas ,': 1, 'pandas , numpy': 1, ', numpy ,': 1, 'numpy , scikit-learn': 1, ', scikit-learn ,': 1, 'scikit-learn , etc': 1, ', etc )': 1, 'etc ) ,': 1, ') , r': 1, ', r ,': 1, 'r , tensorflow': 1, ', tensorflow ,': 1, 'tensorflow , amongst': 1, ', amongst data': 1, 'amongst data science': 1, 'data science related': 1, 'science related tools': 1, 'related tools libraries': 1, 'tools libraries -': 1, 'libraries - analytical': 1, '- analytical mind': 1, 'analytical mind strong': 1, 'mind strong business': 1, 'strong business acumen': 1, \"business acumen 're\": 1, \"acumen 're passionate\": 1, \"'re passionate data\": 1, 'passionate data science': 1, 'data science hungry': 1, 'science hungry learn': 1, 'hungry learn ,': 1, 'learn , please': 1, ', please apply': 1, 'please apply !': 1})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag, ngrams\n",
        "from collections import Counter\n",
        "\n",
        "def extract_skill_keywords(job_description):\n",
        "    # Download NLTK resources (only need to do this once)\n",
        "    nltk.download('punkt')\n",
        "    nltk.download('averaged_perceptron_tagger')\n",
        "    nltk.download('stopwords')\n",
        "\n",
        "    # Preprocess the text and convert to lowercase\n",
        "    job_description = job_description.lower()\n",
        "\n",
        "    # Tokenization\n",
        "    words = word_tokenize(job_description)\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "\n",
        "    # Part-of-Speech (POS) tagging\n",
        "    tagged_words = pos_tag(words)\n",
        "\n",
        "    # Extract skill keywords based on nouns (NN and NNS), noun phrases (NNP and NNPS), bigrams, and trigrams\n",
        "    skill_keywords = [word for word, tag in tagged_words if tag in ['NN', 'NNS', 'NNP', 'NNPS']]\n",
        "    bigrams = [' '.join(bigram) for bigram in ngrams(words, 2)]\n",
        "    trigrams = [' '.join(trigram) for trigram in ngrams(words, 3)]\n",
        "\n",
        "    # Combine single-word, two-word, and three-word keywords\n",
        "    all_keywords = skill_keywords + bigrams + trigrams\n",
        "\n",
        "    # Count and rank skill keywords based on frequency\n",
        "    skill_freq_counter = Counter(all_keywords)\n",
        "\n",
        "    # Optionally, you can create a word cloud or visualize the most common skills using matplotlib\n",
        "\n",
        "    return skill_freq_counter\n",
        "\n",
        "# Example usage\n",
        "job_description_text = \"\"\"\n",
        "\n",
        "Required skills:\n",
        "- BS (or higher, e.g., MS, or PhD) in Computer Science or related engineering field involving coding\n",
        "- Experienced implementing and scaling machine learning models in production environments (including recommendation engines and/or computer vision systems)\n",
        "- Strong understanding of machine learning theory\n",
        "- Hands on experience with Statistics\n",
        "- Capable of quickly implementing prototypes of cutting-edge research papers\n",
        "- Proficient in Python (i.e. Pandas, Numpy, scikit-learn, etc), R, TensorFlow, amongst other data science related tools and libraries\n",
        "- Analytical mind and strong business acumen\n",
        "\n",
        "If you're passionate about data science and is hungry to learn, please apply!\"\"\"\n",
        "skill_keywords = extract_skill_keywords(job_description_text)\n",
        "print(skill_keywords)\n"
      ]
    }
  ]
}